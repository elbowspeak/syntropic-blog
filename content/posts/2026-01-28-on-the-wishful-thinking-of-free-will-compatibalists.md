---
title: On the Wishful Thinking of Free Will Compatibalists
date: 2026-01-28T12:10:00
draft: false
description: ''
image: /images/pachinko_closeup.jpg
image_caption: From the cover of Pachinko by Min Jin Lee
tags:
  - '#Free Will'
  - '#Active Inference'
---

In [Julius's recent Less Wrong post ](https://www.lesswrong.com/posts/tnSagkAADcjRRtbAu/contra-sam-harris-on-free-will)defending compatibilism, they write:

"There is something it feels like to make a choice. As I decide how to open this essay, I have the familiar sense that I could express these ideas in many ways. I weigh different options, imagine how each might land, and select one. This process of deliberation is what most people call 'free will', and it feels undeniably real."

I agree with every word of this except that last clause. The feeling is absolutely vivid and persistent and, IMO,  almost certainly misleading.

The free will debate has run for millennia, and the contemporary version typically arranges itself into three camps.

- Hard determinists say the universe is causally closed, every state follows necessarily from prior states, and free will is therefore illusion.
- Libertarians (in the metaphysical sense, not the political one) say consciousness somehow intervenes in the causal chain, injecting genuine choice into an otherwise mechanical process.
- Compatibilists say we're asking the wrong question, that free will doesn't require escaping determinism, just being the kind of system that responds to reasons, weighs evidence, and acts from its own values rather than external compulsion.

Sam Harris has argued eloquently and forcefully for the hard determinist position, or something close to it. In his telling, consciousness is a witness, not an author. Thoughts appear; we don't summon them. Decisions emerge; we don't make them. The feeling of choosing is what it's like to watch your own neural processes resolve, not what it's like to resolve them.

Julius pushes back from the compatibilist direction, arguing that the "deliberative algorithm", the process of representing options, simulating outcomes, and selecting among them, _is_ free will. The algorithm is you. When it runs, you're choosing.

I think Harris gets the phenomenology mostly right but doesn't fully specify the mechanism. And I think the compatibilists are engaged in wishful thinking that collapses under scrutiny. What follows is my attempt to articulate a third position, one that takes the neuroscience seriously, integrates what we're learning about the mathematics of self-organizing systems, and arrives at a conclusion that is neither classical determinism nor compatibilist rescue.

---

## I. The Pachinko Model

Imagine a pachinko ball dropped into the machine. Its path is determined by the arrangement of pegs (the structure of the system), gravity (deterministic physical law), and tiny perturbations -- vibrations in the machine, imperfections in the ball's surface, air currents, thermal fluctuations at the micro level. Run the same drop twice and you'll get different paths, not because anything spooky intervened but because the perturbations are thermodynamically irreversible. You can't rewind the tape to an identical state.

This is the model I'm proposing for neural decision-making. The brain is a deterministic system in the sense that it obeys physical law, but it operates in a regime where stochastic inputs, neural noise, thermal fluctuations, chaotic sensitivity to initial conditions, constantly perturb the trajectory. The result is neither classical determinism (same inputs, same outputs) nor randomness in the sense of being uncaused. It's path-dependent with probabilistic perturbation. I call this **stochastic determinism**: a system that obeys deterministic laws but whose trajectory is constantly perturbed by noise -- thermal, quantum, environmental -- such that outcomes are unpredictable and non-repeatable without being uncaused or "free."

Now: where is "you" in this model? The compatibilist wants to say you _are_ the system, the whole apparatus of pegs and gravity and ball. When the ball takes a path, that's you choosing. But this conflates the system with the experiencer. Consciousness isn't the machine; it's something more like an observer watching the ball fall, constructing a narrative about why it went left rather than right, and calling that narrative "deliberation."

The crucial claim is that this narrative construction, however sophisticated, is _downstream_ of the process that actually determines the path. Consciousness doesn't steer the ball. It watches the ball and tells a story about steering.

---

## II. Why Compatibilism Doesn't Escape This

Julius's LessWrong post offers a careful articulation of the compatibilist position. They describe decision-making as an algorithm: set a goal, generate options, evaluate each option against your utility function, commit to a decision, act, reflect. They emphasize that this algorithm is causally efficacious, it's not post-hoc narration but the actual process that produces behavior. Give someone a new reason mid-deliberation and they may decide differently. The algorithm responds to reasons, so therefore it's the locus of free will. QED.

There's something right here. The brain-system clearly is reasons-responsive in this sense. Present new evidence and behavior changes. Apply an argument and beliefs update (sometimes). This is what distinguishes humans from thermostats, the complexity and flexibility of the response.

But notice the slippage. Julius says "the algorithm is me" and "my brain doing it is me doing it." This works if we define "me" as the whole physical system. But that's not what the felt sense of free will is about. When I feel like I'm choosing, I don't feel like an algorithm executing. I feel like **_I_**, the locus of experience, the thing that is aware, am the author.

The compatibilist move is to say: stop distinguishing these. The experiencer just _is_ the system. The feeling of authorship just _is_ what it's like to be a reasons-responsive system operating normally.

But this is where the neuroscience becomes uncomfortable. Edmund Rolls' work on stochastic neurodynamics describes what happens when implicit systems (nonconscious processes) drive behavior: the explicit system (conscious processing) confabulates. It generates a plausible-sounding reason for the action and claims authorship. The subject says "I chose X because Y" when in fact the X was selected by processes to which consciousness had no access, and Y is a post-hoc construction.

The compatibilist might respond: fine, but that's a pathological case, or at least an edge case. In normal deliberation, consciousness really is doing the work.

Is it, though? Aaron Schurger's reinterpretation of the famous Libet experiments suggests that the "readiness potential", neural activity preceding conscious awareness of a decision, isn't a signature of unconscious _decision_ but of stochastic neural noise accumulating until it crosses a threshold. The conscious experience of "now I'll act" comes when the threshold is crossed, but the crossing is driven by noise, not by deliberation. John-Dylan Haynes' fMRI work pushes this even further: brain activity patterns can predict which button a subject will press up to seven to ten seconds before the subject reports being aware of the decision.

None of this _proves_ consciousness is epiphenomenal. But it's consistent with a model where consciousness is observing and narrating rather than directing. The timing is wrong for authorship, our awareness comes too late. And the confabulation research shows that the narrative of authorship is generated even when we know the action was driven by something else.

---

## III. Harris Gets Close But Stops Short

Sam Harris's account of free will as illusion captures much of this. He's right that we don't choose our thoughts before we think them, that the sense of authorship doesn't survive close introspection, that the feeling of "could have done otherwise" doesn't track anything real.

But Harris's framing sometimes implies classical determinism; the idea that if we rewound the universe to an identical state, everything would unfold identically. This invites a compatibilist response: "Human behavior is unpredictable even in principle, because the systems are chaotic and we can't access the initial conditions. This unpredictability is where freedom lives."

The stochastic element closes this escape route. Unpredictability doesn't come from conscious intervention, it comes from noise propagating through nonlinear dynamics. The ball's path varies across runs not because something is _choosing_ but because perturbations are constantly injected into a sensitive system. The compatibilist has smuggled "freedom" into the gap created by chaos and noise, but there's no one in that gap.

Derk Pereboom's "hard incompatibilism" is the closest philosophical position to what I'm describing. Pereboom argues that free will is incompatible with determinism (because determined actions aren't authored) _and_ incompatible with indeterminism (because random actions aren't authored either). Whether the underlying process is clockwork or dice, "you" aren't the one making it go.

This is right IMO, but Pereboom frames it primarily as an argument about moral responsibility rather than a positive model of what consciousness is doing. He's clearing ground rather than building on it.

---

## IV. So What Is Consciousness Actually Doing?

The obvious objection: if consciousness isn't authoring decisions, why does it exist? Evolution doesn't maintain expensive metabolic processes for nothing. If conscious experience is just watching a show that would run identically without an audience, what's the selection pressure?

This is where active inference reframes the question more productively.

In the framework developed by Karl Friston and elaborated by researchers like Jeff Beck, consciousness is the process of inference over future states to minimize expected free energy. The brain maintains a generative model of the world, a set of predictions about what sensory inputs to expect given various actions and states. Consciousness is the workspace where these predictions get integrated across modalities and time horizons, where prediction errors are registered, and where the model updates to reduce surprise.

(I should be clear about how much work this claim is doing:  The active inference framework remains contested, and identifying consciousness with predictive inference is a substantive theoretical commitment, not settled science. But the core insight doesn't require buying the full Fristonian apparatus: if consciousness is even roughly in the business of modeling future states, if it's doing prediction and error correction rather than issuing commands, then the compatibilist picture is already in trouble. The question isn't whether this account is complete. The question is whether consciousness is upstream of decision-making (the author) or downstream of it (the model tracking what the system is about to do). The timing evidence, the confabulation research, and the continuity with simpler biological systems all point the same direction.)

Inference is real computational work. It's not "nothing." But here's what collapses the compatibilist position: this process is not unique to what we would define as conscious systems.

Flagella do active inference. A bacterium swimming up a glucose gradient is minimizing expected free energy; it has "expectations" (in the information-theoretic sense) about nutrient concentrations, and it moves to confirm them. Plants do active inference. A sunflower tracking the sun is running prediction and correction to minimize the free energy of its generative model. Single cells, ecosystems... any self-organizing system that maintains itself against entropy is, in the relevant sense, performing inference.

The process the compatibilist points to when they say "that's free will" -- the weighing of options, the evaluation against goals, the selection of action -- is continuous with what happens in a bacterium. The difference is the complexity and temporal depth of the generative model, not the presence of some special "choosing" faculty that bacteria lack and humans possess.

I think this should create a dilemma for the compatibilist.

If "free will" just means "system that minimizes expected free energy through inference over future states," then flagella have free will. The concept is evacuated of meaning. We've defined freedom down to the point where, as an extreme example, a thermostat with a sufficiently complex feedback loop qualifies.

If "free will" requires something more than EFE minimization, some special ingredient that makes human deliberation different in kind from bacterial chemotaxis, then what's that ingredient? The obvious candidate is consciousness itself. But we've just established that consciousness _is_ EFE minimization operating at sufficient complexity and temporal depth. You can't use the phenomenon as its own explanation.

The felt sense of authorship is what it's like to be a system running inference over models of its own future action. To do this inference, the system must represent those actions as "chosen," as "mine," as flowing from "my intentions", because that's the structure of the generative model that minimizes free energy when predicting the behavior of an agent (namely, itself). But, as the saying goes, the map is not the territory. Modeling yourself as an author doesn't make you one. The bacterium doesn't experience authorship because its generative model lacks the recursive complexity to represent itself as a choosing self. You do experience authorship because your model has that structure. But the structure is in the model, not in some homunculus directing traffic.

Consciousness isn't epiphenomenal in the crude sense of "does nothing." It's doing inference, which is computationally essential to the system's function. But inference isn't authorship. The process that selects your actions is the same process but scaled up, more recursive, richer in temporal horizon, that selects the bacterium's direction of travel. Neither of you is "choosing" in the way the folk concept implies. Both of you are minimizing free energy. The only difference is that your system is complex enough to generate a narrative about what it's doing and call that narrative "will."

---

## V. Objections

_"But I can decide to think about elephants right now, and I do. Isn't that consciousness causing something?"_

You experienced the thought "I'll think about elephants" and then experienced thinking about elephants. But the thought to think about elephants arose through the same stochastic-deterministic process we've been describing. You didn't author the intention to think about elephants; you observed the intention arising and then observed the elephants arriving. The causal work ran through the system; consciousness observed both ends.

This feels wrong because the two experiences are closely linked and the narrative of authorship is compelling. But introspect carefully: can you find the moment _before_ you decided to think about elephants, when "you" were the one doing the deciding? Or do you just find... the thought arriving?

_"This position is unfalsifiable."_

Maybe. But notice that the assumption that consciousness _is_ causal is equally unfalsifiable. Any apparent evidence of conscious causation can be redescribed as "the neural correlate of that conscious state caused the behavior." The causal closure of physics means that every physical event has a sufficient physical cause. If conscious experience is identical to certain physical states, then pointing to those states as causes doesn't establish that _consciousness_ (as opposed to the physical process) is doing causal work. The unfalsifiability is symmetric.

What we can do is ask which model better fits the evidence we have: the timing studies showing awareness lagging commitment, the confabulation research showing narrative construction after the fact, the continuity between human inference and bacterial chemotaxis. None of this _proves_ epiphenomenalism. But it should shift credence.

_"If this is true, why does it matter?"_

Because the compatibilist sleight-of-hand has practical consequences. If "you" (the conscious experiencer) aren't actually authoring your decisions, then frameworks of moral responsibility that depend on authorship need revisiting. The retributive intuition, the sense that wrongdoers _deserve_ to suffer for their choices, assumes a kind of authorship that this model denies.

This doesn't mean we abandon responsibility entirely. Harris, Pereboom, and others have argued persuasively that forward-looking, inference over future states considerations (deterrence, rehabilitation, public safety) can ground moral and legal practices without backward-looking desert. The system that constitutes \*you\* still responds to incentives, still learns, still updates. Holding people accountable changes future behavior, regardless of whether anyone is "truly" the author of their actions.

But it does mean we should be suspicious of the emotional satisfaction that comes from blame and punishment. That satisfaction is predicated on a model of authorship that probably doesn't describe how things actually work.

---

## VI. Implications

I want to be clear about what I'm not claiming.

I'm not claiming that decisions are random or arbitrary. The system has structure. It responds to reasons, integrates evidence, pursues goals. The pachinko machine has pegs arranged in a particular pattern, and that pattern shapes the ball's path. Your history, values, beliefs, and habits shape your decisions. This isn't noise all the way down.

I'm not claiming that deliberation is useless. Running inference over future states is how the system navigates. The felt sense of weighing options corresponds to something real happening computationally, multiple possible trajectories being simulated and evaluated against the generative model's expectations. It's just that "you" aren't the one doing the weighing; you're the one experiencing the weighing.

I'm not claiming that life is meaningless or that nothing matters. The system that constitutes you has preferences, attachments, projects. Those don't evaporate just because the folk model of authorship is wrong. What changes is the interpretation: you're not the captain of the ship, you're the passenger who's been handed a very convincing captain's hat.

And I'm not claiming epistemic certainty either. This is a model, informed by current neuroscience and theoretical frameworks like active inference, but hardly proven. The hard problem of consciousness remains hard. Maybe there's something about subjective experience that resists this kind of deflationary treatment? I'm not sure anyone knows yet.

What I am claiming is that the compatibilist rescue fails. You can't save free will by redefining it as "reasons-responsive information processing," because that processing is continuous with what bacteria do, and bacteria don't have free will in any sense worth preserving. The special ingredient the compatibilist needs, the thing that makes human deliberation different in kind, keeps dissolving under examination.

---

## VII. Coda

There's something vertiginous about writing this. The argument I've been making arrived through the very process it describes, stochastic perturbations in neural dynamics settling into attractor states, expected free energy being minimized across a generative model,  complex enough to represent itself making arguments. The feeling that I'm "articulating a position" is the narrative my system generates to make sense of its own operation.

I don't experience it that way, of course. I experience it as thinking, as working something out, as getting closer to truth. That experience is real. It's just not what it seems to be.

The compatibilist will say I'm sawing off the branch I'm sitting on, that if my own reasoning is just inference over future states, then I have no grounds to trust the conclusion. But this proves too much IMO. Either reasoning is trustworthy or it isn't, and that question is independent of whether consciousness is causal. The bacterium's chemotaxis is "trustworthy" in the sense that it generally gets the bacterium to glucose. My reasoning is trustworthy in the sense that it generally builds models that predict experience and enable navigation. Neither of us is "choosing" to reason well; we're both systems that minimize free energy by updating our generative models. The validity of the conclusion doesn't depend on the felt sense of authorship being accurate.

So here we are. You didn't choose to read this essay, though it feels like you did. I didn't choose to write it, though the narrative of authorship is vivid and persistent. We're both pachinko balls, dropped into machines of staggering complexity, bouncing off pegs we didn't place, perturbed by noise we can't control, experiencing the path as a journey we're taking rather than a trajectory we're tracing.

The compatibilist wants to say: that's enough. That's all "free will" ever meant.

I think that's wishful thinking. But I would say that, wouldn't I? The ball always thinks it's steering.

---

## References

- Harris, Sam. _Free Will_ (2012)
- Julius. "Contra Sam Harris on Free Will." LessWrong (2026)
- Pereboom, Derk. _Living Without Free Will_ (2001)
- Rolls, Edmund T. "Willed action, free will, and the stochastic neurodynamics of decision-making." _Frontiers in Integrative Neuroscience_ (2012)
- Schurger, Aaron, et al. "An accumulator model for spontaneous neural activity prior to self-initiated movement." _PNAS_ (2012)
- Haynes, John-Dylan. "Decoding and predicting intentions." _Annals of the New York Academy of Sciences_ (2011)
- Friston, Karl. "The free-energy principle: a unified brain theory?" _Nature Reviews Neuroscience_ (2010)
