---
title: Meditations on the God of Spinoza
date: 2026-01-31T16:58:00
draft: false
description: ''
image: /images/Webb-Pillars-of-Creation-1536x970-3049760444.jpg
image_caption: The PIllars of Creation, Hubble Telescope
tags: []
---

Begin with what we know.

The universe had a beginning: the Big Bang, the initial singularity, the boundary we can't see beyond. From that beginning emerged space, time, and energy in distributions of varying density. Some of those densities collapsed under their own gravity and ignited into stars. Those stars generated energy gradients of staggering magnitude: fusion furnaces pouring radiation into the void -- and onto smaller orbiting densities, planets, bathed in their radiation.

The second law of thermodynamics governs what follows.

---

## The Telos of Entropy

The second law tells us that entropy increases. Energy disperses and gradients dissipate. This is the asymmetry that determines which configurations of matter are accessible from which others, and in what direction time flows. If you want to know why the universe looks the way it does rather than some other way, the answer is: because entropy increases.

I use the word **telos** here deliberately, knowing it will raise objections. Telos implies purpose, goal, intention; concepts that seem to smuggle theology back into a universe we have spent centuries stripping of divine purpose. But I mean something more precise: telos in the Hegelian sense of an underlying dynamic that pushes things in a certain direction,  a constraint that determines which paths are traversable and which are not.

Consider that you don't get from the Big Bang to the heat death of the universe without the second law operating as this kind of constraint. The low-entropy initial state, with matter and energy concentrated in ways that permitted the formation of structure, gives way inexorably to states of higher entropy. This is the statistical reality of how microstates relate to macrostates, how probable configurations vastly outnumber improbable ones, how any system with sufficient degrees of freedom will explore its phase space in ways that increase entropy over time.

The second law emerges from the mathematics of statistical mechanics and is the constraint within which everything else unfolds. Stars, planets, chemistry, life, mind, etc. are all downstream of that gradient.

We might, of course, be wrong. Our current understanding of physical law might be incomplete in ways that would revise this picture. But within the physics we have, entropy is as close to a cosmic direction as we get. We're not trying to sneak purpose in through the back door. We're merely noting that the universe has a direction. And that direction is entropy. And everything else, including us, is a consequence of how entropy gets produced along the way.

---

## Dissipative Structures and the Thermodynamics of Organization

Entropy is commonly glossed as "disorder," and this gloss has done more harm than good. It suggests that the universe tends toward homogeneous chaos, that organization is always fighting against the cosmic tide, that life and mind are improbable exceptions clinging to existence against the overwhelming pressure toward dissolution.

This picture misleads in ways that obscure the most important features of thermodynamic reality.

Entropy is better understood as the dispersal of energy, the spreading out of gradients, the transition from concentrated to diffuse configurations. A hot cup of coffee cooling to room temperature increases entropy not because the molecules become more "disordered" in any intuitive sense, but because the thermal energy that was concentrated in the coffee spreads out into the surrounding environment. The gradient between coffee and room has been dissipated.

Consider what happens when you have a persistent energy gradient that continuously pours low-entropy energy into a system. This is the situation on any planet orbiting a star, receiving and absorbing a constant stream of concentrated energy. Under these conditions, something remarkable can occur. **The system can develop structures that accelerate the dissipation of the gradient.** These are what Ilya Prigogine, who won the Nobel Prize for his work on non-equilibrium thermodynamics, called "dissipative structures." {{< cite 1 2 >}}

The canonical example is the Bénard cell, a container of fluid heated from below. At low temperature gradients, heat moves through the fluid by conduction. This is the slow, molecule-by-molecule transfer of thermal energy. But something surprising happens when the gradient exceeds a critical threshold, the system spontaneously organizes into convection cells, hexagonal patterns of rising and falling fluid that transport heat far more efficiently than conduction alone. The system has developed structure, organization that would seem to decrease entropy locally. But this local decrease is more than compensated by the increased rate of entropy production globally. The convection cells exist because they dissipate the gradient more effectively.

The insight is that organization can be thermodynamically favored when it serves entropy production. The second law doesn't prohibit **_local_** decreases in entropy, but it does require that any local decrease be paid for by a larger increase elsewhere. Dissipative structures are the universe's way of finding efficient channels for gradient destruction.

---

## Life as Thermodynamic Inevitability

The old framing positioned life as fighting against entropy, the delicate order maintained in defiance of the universe's tendency toward disorder. Schrödinger's famous question, "What is life?" {{< cite 14 >}}, was framed in terms of how living things manage to maintain their organization against the entropic tide. But the framing inverts the actual relationship. Life doesn't defy entropy, it _accelerates_ entropy.

The physicist Jeremy England, working at MIT and later Georgia Tech, formalized this insight in a series of papers beginning in 2013. His framework, which he calls "dissipation-driven adaptation," argues that under certain conditions, groups of atoms will naturally restructure themselves to absorb and dissipate energy more effectively {{< cite 5 6 >}}. The equations of non-equilibrium statistical mechanics, particularly the fluctuation theorems developed by Crooks, Jarzynski, and others in the 1990s, provide the mathematical foundation {{< cite 3 4 >}}: systems driven far  away from equilibrium by external energy sources will tend toward configurations that efficiently absorb and dissipate that energy.

Classical thermodynamics describes systems at or near equilibrium. The fluctuation theorems provide the mathematical relationships for systems driven far from equilibrium. These theorems show that the probability of a transition to a far from equilibrium state is related to the entropy it produces. In a system driven by energy gradients, configurations that absorb and dissipate energy more effectively become statistically more probable over time. England's contribution was to apply this framework to self-replicating systems, showing that the thermodynamic conditions favoring efficient dissipation are also conditions favoring the emergence of life-like organization.

England's claim is strong: "You start with a random clump of atoms, and if you shine light on it for long enough, it should not be so surprising that you get a plant" {{< cite 7 >}}. Life, in this view, is not a mysterious exception to physics but an expected consequence of thermodynamics operating on matter in the presence of persistent energy gradients.

The empirical support for this framework has been accumulating. The surface layer of seawater produces between 30% to 680% more entropy when cyanobacteria and other organic matter are present than when they are absent {{< cite 16 >}}. Modeling studies by Meysman, Bruers, and others have confirmed that across a range of ecosystem configurations, living systems consistently produce more entropy than their abiotic counterparts given the same boundary conditions {{< cite 8 >}}. As the ecologist Joseph Vallino has argued, biological systems outperform abiotic processes in entropy production by maximizing dissipation over longer timescales rather than instantaneously {{< cite 9 >}}; a point to which we will return.

A rainforest dissipates solar energy gradients more effectively than bare rock. A planet teeming with photosynthetic life converts incoming sunlight to outgoing infrared radiation (low-entropy photons to high-entropy photons) more efficiently than a dead world of the same size and composition. Life accelerates the current.

This reframes the question of life's origin entirely. Now we can ask, given persistent energy gradients, given the fluctuation theorems, given the tendency of driven systems to find efficient dissipative configurations, why _wouldn't_ something like life emerge? The question shifts from "how did life beat the odds?" to "what are the conditions under which dissipative structures become self-replicating?"

The channel happens to be self-replicating, error-correcting, and adaptive, because those properties make it even better at dissipating gradients over time. A single organism dissipates energy; a population of organisms dissipates more; a population that can adapt to changing conditions maintains its dissipative capacity longer. Evolution is what thermodynamic optimization looks like when the dissipative structures can copy themselves with variation.

---

## Temporal Arbitrage: The Distinction Between Living and Non-Living Dissipative Structures

The insight that life accelerates entropy production raises an immediate question: if entropy production is the criterion, why doesn't the fastest dissipater always win? A fire dissipates energy very rapidly. A nuclear explosion dissipates energy faster still. Why isn't the biosphere a continuous conflagration rather than a patient accumulation of biomass?

The answer lies in the temporal structure of dissipation. Abiotic systems maximize entropy production instantaneously. They take the steepest descent down the energy gradient, like a rock rolling downhill. A fire burns hot and fast, but it also burns out. Once the fuel is consumed, the dissipation stops. The fire has maximized its instantaneous entropy production at the cost of its persistence.

Biological systems operate differently. They maximize entropy production integrated over time. This is Vallino's insight {{< cite 9 >}}: the difference between abiotic and biotic processes is that the former always follow the pathway of steepest descent, while the latter follow pathways dictated by information-theoretic entropy optimization, which leads to greater entropy production when summed over extended periods.

Think about the rock-rolling-downhill analogy more carefully. The steepest descent path might lead the rock into a ditch halfway down, where it gets stuck. A "smarter" path, one that curves around the ditch, would have lower instantaneous gradient destruction but would ultimately dissipate more gravitational potential energy by reaching the bottom. Biological systems, in effect, have learned to take the smarter path. They store information in genomes, in neural architectures, in cultural practices, that allows them to navigate the energy landscape in ways that sustain dissipation over time.

This is where prediction enters the picture. To maximize entropy over time rather than instantaneously, a system must model its environment and its own future states. It must anticipate. The organism that can predict where food will be tomorrow is more likely to still be alive tomorrow, still dissipating, still contributing to the entropy budget of the universe. The organism that can predict seasonal changes can store resources, migrate, or enter dormancy; strategies that sacrifice short-term dissipation for long-term persistence of dissipative capacity.

Active inference, the framework developed by Karl Friston and collaborators, formalizes this insight {{< cite 11 12 >}}. Living systems are prediction machines. They maintain models of their environment and act to minimize the divergence between their predictions and their sensory observations. The mathematics here is rigorous, grounded in variational principles. Prediction is central to life because it enables temporal arbitrage: trading instantaneous dissipation for sustained dissipation, sacrificing the steepest descent for the longer path.

---

## Humans as Planetary-Scale Dissipators

And then there are humans. We have become temporal arbitrageurs of entropy on a planetary scale, though our arbitrage now operates at timescales that dwarf individual lifetimes.

The petroleum and coal deposits that accumulated over hundreds of millions of years represent stored sunlight from the Carboniferous period. Ancient forests captured solar energy through photosynthesis, died, were buried, compressed, transformed by geological processes into concentrated chemical potential energy. This was entropy arbitrage performed by the Earth system itself: capturing energy flows, storing them in stable molecular configurations, sequestering them in geological formations where they could persist for eons.

We are burning through these reserves in centuries. The fossil fuel era represents an extraordinary acceleration of planetary entropy production. We have unlocked dissipative channels that dwarf anything biology achieved before us. We burn gas. We burn wood at rates far exceeding natural occurrence. We have consumed a significant fraction of fossil fuel reserves that took geological ages to accumulate.

Consider the sheer magnitude: hundreds of millions of years of accumulated solar energy, dissipated in a few hundred years. The ratio is staggering. Whatever else we are, whatever else we mean, we are the most effective entropy-producing configuration that this planet has yet achieved. Our industrial civilization is a dissipative structure of unprecedented power.

The observation carries moral weight, but it begins as an observation about our thermodynamic role. The climate crisis, from this vantage, is a consequence of dissipating too fast; burning through stored energy gradients faster than the planetary system can accommodate the resulting heat. The sustainability question becomes: how do we maintain our dissipative capacity over longer timescales? How do we avoid the fate of the fire that burns hot and fast and then goes out?

The irony here is potent: our very success as entropy producers may undermine the conditions for our continued thriving. This is the temporal arbitrage problem at civilizational scale. We have optimized for instantaneous dissipation -- economic growth, energy consumption, material throughput -- at the potential cost of long-term persistence. The question is whether we can learn to take the smarter path, the one that curves around the ditch, the one that reaches the bottom of the hill rather than getting stuck halfway down.

---

## Dissolving the Hard Problem

We have traced a path from the Big Bang through thermodynamic gradients, dissipative structures, the emergence of life, the evolution of prediction, and the peculiar status of humans as planetary-scale entropy producers. Now we need to address the question that haunts all materialist accounts of mind: consciousness.

The so-called hard problem of consciousness, articulated most influentially by David Chalmers, asks why experience exists at all -- not why we process information, that's the easy part, at least in principle. The hard part is why processing feels like anything. When light of a certain wavelength hits your retina and your visual system categorizes it, why is there also a redness to the experience? Why isn't the processing just processing, silent and dark from the inside? A thermostat detects temperature and adjusts accordingly, but there's presumably nothing it is like to be a thermostat. Why should there be something it is like to be you?

We can imagine, or so the argument goes, a "zombie" physically identical to you, same neurons, same computations, same behavioral outputs, but with no inner experience, no felt quality to any of it. The lights are on but nobody's home. If such a zombie is even conceivable, then the functional explanation seems to leave something out. You can describe all the machinery and still not have explained why the machinery is accompanied by experience. There is an explanatory gap between what the brain does and what the mind feels.

The gap feels unbridgeable because we're trying to interpret a hidden state from outside the system that generates it. But consider what a self-model is for: an organism that can model itself, that can represent its own states, predict its own responses, simulate its own future behavior -- this capability has significant fitness advantages. It can engage in counterfactual reasoning: what would happen if I did this rather than that? It can catch errors before they become fatal: wait, that action would conflict with my goals. It can coordinate its behavior over time: I need to remember that I am the same agent who made that commitment yesterday.

The self-model is a tool for navigating the world more effectively. And a self-model that represents itself as a unified, continuous, experiencing subject is more useful than one that doesn't. The "feeling" of being a self, of being the captain of one's own ship, of having experiences that are mine in some irreducible sense... this feeling is part of the machinery's operation, not a mysterious addition to it.

When we introspect -- and introspection is itself a process within the self-model, not a window onto something separate -- we encounter the self-model's outputs. The felt quality of experience, the "what it is like" that seems so resistant to functional explanation, is generated by the model: hunger as metabolic deficit, fear as predicted threat, pleasure as what worked before.

The hard problem dissolves when we recognize that there is no gap—only a self-model that represents itself as irreducible because that's a useful way to organize behavior. The model isn't designed to explain itself from outside; it's designed to operate, navigate, predict, act. The sense that something is left over after all the functional explanation is complete is a mistaken interpretation, created by the inability of the model to see itself from outside.

This feeling of experience is real, as real as anything. You're not imagining the redness of red or the sting of pain. The mistake is thinking that because it feels irreducible, it must be something separate from the physical process. But the _feeling of experience_ is just what the machinery feels like when it's running.

---

## The Grounding Problem

Years ago, I had a conversation with one of my philosophy professors about religion. I said something to the effect that religion is made up, not grounded in anything except human desire for comfort and certainty. He asked: then tell me, what is grounded?

At the time, I couldn't articulate an answer. Now I can.

People are drawn to religion and religious communities because adopting a belief system and a community of practice reduces their uncertainty enough to make them feel centered and comfortable. I state this as observation rather than a criticism. We are prediction machines, and prediction machines need models of the world to function. Uncertainty is costly; it degrades our ability to act, to plan, to coordinate with others. Frameworks that reduce uncertainty provide genuine psychological benefits.

Some people have high tolerance for uncertainty. They can function without comprehensive answers to the big questions, as long as their local uncertainty -- will I eat tomorrow, will my relationships persist, will my projects succeed -- remains manageable. But for many people, perhaps most, the existential questions press in and require a comfortable answer: why is there something rather than nothing? What happens when I die? Does my life have meaning? Does the universe care?

Religion offers answers to these questions. It grounds belief in revelation: something someone said happened, which you must accept on authority. A burning bush, a voice from heaven, a prophet's vision, a sacred text passed down through generations. The ground of religious belief is testimony: someone encountered the divine, and I trust their report.

The problem with testimony as ground is that it requires you to stop asking questions at a certain point. You can ask how the universe began, and religion will tell you God created it. But you can't ask what grounds the existence of God, or if you do, the answer will be that God is self-grounding, necessary, beyond the need for further explanation. At some point, you must simply believe. The old man in the sky, or the Ground of Being, or the Absolute, or whatever sophisticated theological concept you prefer, requires faith precisely where inquiry would be most valuable.

The second law of thermodynamics is not a belief that requires faith. It is an observation about how reality behaves, confirmed by every experiment ever conducted. You don't need to believe in entropy increasing; you can watch ice melt. You can measure the heat dissipated by a running engine. You can observe the cosmic microwave background radiation and trace its implications back to a low-entropy initial state. The second law is a regularity to be observed, tested, refined, and integrated into an ever-more-comprehensive understanding of how the universe works.

And from that single, empirically unassailable principle, you can derive an extraordinary account of reality.

1. **The direction of time:** why we remember the past but not the future, why causes precede effects, why we age.
2. **The existence of energy gradients**: concentrations of low-entropy energy that can do work, that can drive processes, that can power dissipative structures.
3. **The emergence of organization:** how systems far from equilibrium develop structures that accelerate entropy production.
4. **The inevitability of self-organization:** how persistent gradients give rise to increasingly complex dissipative structures, including self-replicating ones.
5. **The fitness advantage of prediction:** how systems that model their environment can sustain dissipation over longer timescales.
6. **The functional necessity of self-models:** how prediction machines that represent themselves can navigate more effectively.
7. **The felt sense of being a subject:** how self-models generate the phenomenology of experience.

The chain is long, and each link requires detailed argument and empirical support. Filling in the details is the work of physics, chemistry, biology, neuroscience, and philosophy collaborating across their traditional boundaries. But the crucial point is that each step is open to inquiry. There is no moment where you have to stop asking questions and simply believe. The ground isn't faith; the ground is the universe, and the universe can be investigated.

Both frameworks provide uncertainty reduction. Both offer answers to the big questions. But one is defensible at every level of inquiry; the other requires you to stop asking questions at a certain point. One grounds belief in observation and inference; the other grounds belief in testimony and faith. One requires you to trust that ice melts, that engines dissipate heat, that the universe behaves in regular and investigable ways; the other requires you to trust what someone said about an encounter with the divine.

I know which ground I find more secure.

---

## Deus Sive Natura

Baruch Spinoza, writing in the seventeenth century, was excommunicated from the Jewish community of Amsterdam for his heretical views. What was his heresy? He denied the distinction between God and Nature. **Deus sive natura**, God or nature {{< cite 15 >}}. Spinoza said that the sacred and the causal aren't separate domains, they're the same thing viewed from different angles. There is no transcendent creator standing outside the universe, directing it from beyond. There is only the universe, and what we call "God" is a name for its immanent order, its self-organizing principles, its capacity to generate structure and complexity and mind.

Spinoza understood this three and a half centuries before non-equilibrium thermodynamics, before dissipative structures, before the fluctuation theorems, before active inference. He grasped, through philosophical reasoning alone, the shape of the answer that physics would eventually provide: there is no deus ex machina descending from outside the system to inject life, mind, or meaning. It is machina all the way down.

An interesting aside: Jeremy England, whose work on dissipation-driven adaptation provides much of the scientific foundation for this meditation, is himself an Orthodox Jew and ordained rabbi. How he reconciles his physics with his faith is his own affair, but I confess I find it puzzling. The very framework he has developed -- showing how thermodynamics makes life not merely possible but probable, how the emergence of complex organization follows from the mathematics of non-equilibrium systems -- seems to me to render the hypothesis of divine creation not wrong, exactly, but superfluous. The machina explains the phenomena that the deus was invoked to explain. What work, then, is left for God to do?

Perhaps England would say that God is the ground of the laws themselves, that thermodynamics operates because God ordained it so. But this is the move I find unsatisfying: it pushes the question back one level without answering it, and then declares the question closed. Why these laws and not others? Because God. Why God? Because God is self-grounding. At some point, you must simply believe.

I prefer to stop where the questions can still be asked. We don't know why the laws of physics are what they are. Perhaps there is a deeper explanation, perhaps there is not. Perhaps the question is malformed in ways we don't yet understand. But "God did it" is not an answer to this question. It is a way of declaring the question closed.

Spinoza saw this. The universe doesn't need a transcendent ground because the universe is its own ground. **Deus sive natura**. The sacred and the causal are the same thing.

The crude mechanistic worldview misses what Spinoza grasped and what I have been trying to articulate: the machina is extraordinary. The universe isn't a dead mechanism with meaning projected onto it by humans. The universe is a mechanism that generates complexity, modeling, experience. The machinery produces prediction engines that navigate uncertainty, maintain themselves far from equilibrium, and in some configurations become aware of their own existence.

The mechanistic picture is often presented as a demotion, a stripping away of purpose and value, a reduction of everything meaningful to the meaningless motion of particles. Such presentations fail imagination. The mechanistic picture, properly understood, is a revelation. The same principles that govern heat engines and diffusion gradients also govern the emergence of life and the generation of experience. The same mathematics that describes a cup of coffee cooling describes a biosphere dissipating solar radiation. The universe is one thing, governed by one set of laws, and those laws are capable of producing beings that wonder about them.

One can think of it as an elevation of the natural to the status that religion reserves for the supernatural. The **ground of being** isn't an old man in the sky, nor an abstract principle requiring faith, nor a mystery beyond inquiry. The ground of being is thermodynamics, and thermodynamics produces us.

We don't need a deus ex machina. The machina is sufficient. The machina is, in fact, more wondrous than any God humans have invented, because it is real, and it made us, and we can understand it.

There is grandeur in this view. Not the false grandeur of imagined cosmic purpose, of a universe that exists for our sake, of a deity that cares about our prayers and our sins. The real grandeur is of a universe that generates complexity from simplicity, mind from matter, experience from entropy gradients. We are not the point of the cosmos. We are something far more interesting: we are the cosmos becoming aware of itself, one dissipative structure among countless others, temporary and contingent and astonishing.

That is Spinoza's God. And that is enough.

---

## Sources

<ol class="reference-list">
{{< ref 1 "Prigogine, Ilya. _Introduction to Thermodynamics of Irreversible Processes_. Wiley, 1967. [Archive.org](https://archive.org/details/introductiontoth0000prig)" >}}
{{< ref 2 "Prigogine, Ilya and Nicolis, G. \"Biological order, structure and instabilities.\" _Quarterly Reviews of Biophysics_ 4, 107–148, 1971. [Cambridge Core](https://doi.org/10.1017/S0033583500000615)" >}}
{{< ref 3 "Crooks, Gavin E. \"Entropy production fluctuation theorem and the nonequilibrium work relation for free energy differences.\" _Physical Review E_ 60, 2721, 1999. [APS Physics](https://doi.org/10.1103/PhysRevE.60.2721)" >}}
{{< ref 4 "Jarzynski, Christopher. \"Nonequilibrium Equality for Free Energy Differences.\" _Physical Review Letters_ 78, 2690, 1997. [APS Physics](https://doi.org/10.1103/PhysRevLett.78.2690)" >}}
{{< ref 5 "England, Jeremy L. \"Statistical physics of self-replication.\" _Journal of Chemical Physics_ 139, 121923, 2013. [AIP Publishing](https://doi.org/10.1063/1.4818538)" >}}
{{< ref 6 "England, Jeremy L. \"Dissipative adaptation in driven self-assembly.\" _Nature Nanotechnology_ 10, 919–923, 2015. [Nature](https://doi.org/10.1038/nnano.2015.250)" >}}
{{< ref 7 "Wolchover, Natalie. \"A New Physics Theory of Life.\" _Quanta Magazine_, January 22, 2014. [Quanta Magazine](https://www.quantamagazine.org/a-new-thermodynamics-theory-of-the-origin-of-life-20140122/)" >}}
{{< ref 8 "Meysman, Filip J.R. and Bruers, Stijn. \"Ecosystem functioning and maximum entropy production: a quantitative test of hypotheses.\" _Philosophical Transactions of the Royal Society B_ 365, 1405–1416, 2010. [Royal Society](https://doi.org/10.1098/rstb.2009.0300)" >}}
{{< ref 9 "Vallino, Joseph J. \"Ecosystem biogeochemistry considered as a distributed metabolic network ordered by maximum entropy production.\" _Philosophical Transactions of the Royal Society B_ 365, 1417–1427, 2010. [Royal Society](https://doi.org/10.1098/rstb.2009.0272)" >}}
{{< ref 10 "Kleidon, Axel and Lorenz, Ralph D., eds. _Non-equilibrium Thermodynamics and the Production of Entropy: Life, Earth, and Beyond_. Springer, 2005. [Springer](https://doi.org/10.1007/b12042)" >}}
{{< ref 11 "Friston, Karl. \"The free-energy principle: a unified brain theory?\" _Nature Reviews Neuroscience_ 11, 127–138, 2010. [Nature](https://doi.org/10.1038/nrn2787)" >}}
{{< ref 12 "Friston, Karl. \"Life as we know it.\" _Journal of the Royal Society Interface_ 10, 20130475, 2013. [Royal Society](https://doi.org/10.1098/rsif.2013.0475)" >}}
{{< ref 13 "Chalmers, David J. \"Facing Up to the Problem of Consciousness.\" _Journal of Consciousness Studies_ 2(3), 200–219, 1995. [David Chalmers' website](http://consc.net/papers/facing.html)" >}}
{{< ref 14 "Schrödinger, Erwin. _What Is Life?_ Cambridge University Press, 1944. [Cambridge Core](https://doi.org/10.1017/CBO9781139644129)" >}}
{{< ref 15 "Spinoza, Baruch. _Ethics_. 1677. [Project Gutenberg](https://www.gutenberg.org/ebooks/3800)" >}}
{{< ref 16 "Veritasium. \"The Most Misunderstood Concept in Physics.\" YouTube, 2023. [YouTube](https://www.youtube.com/watch?v=DxL2HoqLbyA)" >}}
</ol>
