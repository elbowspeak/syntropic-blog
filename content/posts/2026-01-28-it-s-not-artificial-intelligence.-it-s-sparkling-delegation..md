---
title: It's not Artificial Intelligence. It's Sparkling Delegation.
date: 2026-01-27T16:55:00
draft: false
description: ''
image: /images/6758_Mirga_08_(C)_Daniela_Schmidt-Langels.jpg
image_caption: Mirga Gražinytė-Tyla, Birmingham Symphony Orchestra
tags:
  - '#AI'
---

The term Artificial Intelligence is sabotaging how you use AI tools. A more useful framing is **automated delegation technology**.

The term Artificial Intelligence is itself a marketing rebrand. As Signal president Meredith Whittaker [observed from her years inside Google](https://www.cityarts.net/event/the-future-of-civil-liberties-privacy-ethics-in-tech/), "AI is an overhyped marketing term". Engineers call it machine learning, but if you want that Series A, you're selling AI.

**_Delegation_** carries decades of accumulated wisdom about what makes managing projects or people succeed or fail. Some managers reliably multiply their teams' output while others inherit talent and squander it. Mapping AI onto that existing knowledge reveals patterns that the "intelligence" frame obscures.

## The Delegation Metaphor

Think about the best delegator you know, someone who consistently gets extraordinary results working with their team. What makes them effective has almost nothing to do with having the smartest people, plenty of managers inherit talented teams and squander them while others build remarkable output from average resources.

The difference lies in the delegator's own capabilities. They specify outcomes with precision, translating fuzzy goals into concrete targets and anticipating ambiguity before it metastasizes into weeks of wasted effort. They calibrate task complexity to capability and match the specificity of their direction to what the situation actually requires. They supervise without suffocating, build in checkpoints and course-correct early instead of discovering problems at the end. And when things go wrong, they examine their own instructions and assumptions rather than simply blaming the person they delegated to.

Bad delegators dump complex work on people without context, support, or check-ins. They treat delegation as a joyful abdication of responsibility: throw a bunch of crap over the wall and hope for the best. But then they blame their team for the disappointing results.

Most organizations are bad delegators when it comes to AI. They approach these tools the way a poor manager approaches a new hire: unclear direction, poor scaffolding, no supervision structure, unrealistic expectations, and then frustration when things don't work out. But **AI capability isn't the constraint anymore**.

Most organizations already have access to models that far exceed their ability to use them well. Current models can write, analyze and code, plus research and synthesize at levels that were science fiction just a few years ago. The constraint is now our own judgement and problem solving. It's our ability to specify what we want, our skill at breaking complex challenges into delegable (delegate-able?) pieces, our discipline around supervision and iteration, and our willingness to rethink workflows rather than just "make them 20% faster/better".

## AI Underperformance

Once you see AI as delegation, three failure patterns emerge.

### Path Dependence

Path dependence means optimizing within current constraints instead of questioning whether those constraints still apply. You have a process that takes four people and three days, you bring in AI to make it faster, now it takes four people and two days. But you might be optimizing a workflow that shouldn't exist in that form at all.

The delegation frame forces a different question: if I were starting from scratch with this new capability, would I design the process this way at all? Usually the answer is no. Path dependence feels safe because it's incremental, improving what exists rather than reimagining it, but incremental improvement of a constrained design has limits. You can make a horse-drawn carriage more aerodynamic without ever addressing the fact that it's a carriage drawn by a horse.

### Information Bottlenecks Persist

This pattern looks like progress while leaving the underlying architecture unchanged. Organizations bolt AI onto human bottlenecked workflows without identifying and addressing the bottleneck itself.

Here's a typical scenario: customer inquiries come in and sit in a queue. A person eventually reviews and categorizes them, with each category getting its own queue. Specialists eventually handle them. This all takes a lot of time, so you deploy AI to help the specialists work faster. Great! Now each case is handled 30% quicker. But you've optimized a step that represents not even 20% of total cycle time. This is the equivalent of making one traffic light faster on a route that has twelve of them that are timed differently.

Good delegation asks where work is actually getting stuck, what the rate limiting step is, and whether AI could change which steps are rate limiting at all. Sometimes that means AI shouldn't make humans faster but should replace human dependent chokepoints entirely, moving those humans to judgment intensive work that actually requires them.

### Anchored Aspiration

This might be the most costly pattern because it feels like success. Anchored aspiration means benchmarking against pre-AI possibilities rather than post-AI potential, then celebrating outcomes that would have been impressive in 2022.

- "We reduced report generation time by 20%."
- "Our analysts can now handle 50% more cases."
- "First-draft quality improved significantly."

These sound good. And relative to past performance, they probably are good. But they also likely represent a fraction of what's actually possible. When you delegate to a capable resource, **the question is no longer how much faster you can do what you did before, but what becomes possible that wasn't possible before**.

A 20% improvement in report generation time might be the wrong metric entirely if AI could enable real-time continuous analysis that eliminates discrete reports altogether. Handling 50% more cases might miss the point if AI could prevent most of those cases from arising in the first place.

Anchored aspiration keeps you playing the same game when that game has been made obsolete by new automation capabilities. **Our job now is to break free of our fetters, to expand our scope of aspiration.**

## Why This Reframe is Helpful

The delegation frame shifts the bottleneck from technology to human capacity, and this shift changes where you look for answers when designing new protocols and processes.

When you think of AI as intelligence, underperformance points to technological limits, the model isn't smart enough, the training data is insufficient, the architecture is wrong, and the solution is always, "we need better technology," which conveniently places responsibility outside your organization.

When you think of AI as delegation, underperformance points to human practices: your specification was unclear, your supervision was insufficient, your feedback loops were too slow, your aspiration was too anchored. The solution is better delegation. But most people have never delegated to something this capable, and the habits they've built don't transfer cleanly.

It's easier to blame the tool or the vendor than to examine our own capabilities. But it's also harder to something about. You can't make the AI smarter (the frontier models are what they are, and they're already remarkably capable). But you **can** get better at specifying outcomes, you **can** build stronger supervision structures, you **can** create faster feedback loops, you **can** force yourself to question path-dependent assumptions, and you **can** raise your aspiration level. **In short, you can become a better delegator**.

## So What Do I Do?

If the bottleneck is human delegation capability rather than AI capability, your strategy changes.

**Invest in specification skills.** The ability to translate fuzzy business goals into precise, delegable instructions is now a core competency. It's trainable, but most organizations aren't training it. They're buying "better" tools for people who don't know how to use the tools they already have.

**Design for supervision.** Every AI deployment needs clear checkpoints, review processes, and feedback mechanisms. Build the supervision infrastructure before you deploy, not after things go wrong.

**Question the workflow before accelerating it.** Before you bolt AI onto an existing process, ask whether this process should exist in this form at all, what constraints it was designed around, and whether those constraints still apply. **_The highest value AI initiatives often start with process redesign rather than process acceleration._**

**Benchmark against possibility.** Stop asking how much better than before and start asking what's now achievable. This requires imagination and courage. It's easier to claim incremental improvement than to stake out a fundamentally different vision. But conservative anchored aspiration is leaving enormous value on the table.

**Own the bottleneck.** When AI initiatives underperform, look in the mirror before you look at the vendor. The technology is capable. The question is whether your organization is capable of using it well.

The age of AI is really the age of automated delegation at unprecedented scale, and the organizations that thrive will be the ones that learn to delegate best.
