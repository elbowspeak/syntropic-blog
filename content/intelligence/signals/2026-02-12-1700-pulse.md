---
title: "SMIC Warns of AI Chip Capacity Oversupply Risk"
date: 2026-02-12
time: 17:00
stream: signals
layout: intelligence-single
---
# Intelligence Pulse - 2026-02-12 17:00
Based on my scan of the last 24 hours, here are the AI supply chain signals:

## Signals

### Compute | SMIC Warns of AI Chip Capacity Oversupply Risk
- What: 
China's SMIC warned that companies want to build 10 years' worth of AI data center capacity in 1-2 years, raising the risk of idle capacity

- Impact: Potential oversupply in AI chip manufacturing capacity could lead to price collapse and stranded assets; affects fab buildout timelines and equipment orders
- Confidence: High
- Source: Taipei Times (16 hours ago)

### Compute | MediaTek Doubles Down on Data Center AI Chips
- What: 
MediaTek plans to double investment in data center technologies including advanced packaging, forecasts data centers to become second-biggest revenue source in three years

- Impact: Major smartphone chipmaker pivoting to AI infrastructure signals sustained demand; increases competition in ASIC/custom AI chip market
- Confidence: High
- Source: Taipei Times (16 hours ago)

### Compute | Applied Materials Ships 2nm GAA Manufacturing Systems
- What: 
Applied Materials unveiled new equipment for 2nm Gate-All-Around transistors at SEMICON Korea, targeting AI chip bottlenecks

- Impact: Critical for next-gen AI chip manufacturing timeline; affects TSMC/Samsung 2nm ramp schedules
- Confidence: High
- Source: Futurum Group (1 day ago)

### Compute | Memory Revenue to Hit $551B in 2026, Double Foundry Revenue
- What: 
TrendForce projects 3D NAND and DRAM revenue will reach $551.6 billion versus $218.7 billion for foundries, driven by AI buildouts creating memory shortages

- Impact: Memory makers (Samsung, SK Hynix, Micron) capturing more AI boom value than chip designers; HBM shortage persists for years
- Confidence: High
- Source: Tom's Hardware (2 days ago)

### Models | OpenAI Ships GPT-5.2 with Enterprise Focus
- What: 
OpenAI released GPT-5.2 targeting professional knowledge work, sets new state-of-the-art on GDPval benchmark across 44 occupations

- Impact: Shifts model competition toward enterprise productivity vs raw intelligence; increases inference demand
- Confidence: High
- Source: OpenAI official (recent)

### Deployment | Inference Now 55% of AI Infrastructure Spending
- What: 
Inference represents 55% of AI infrastructure spending in early 2026, up from 33% in 2023, projected to reach 75-80% by 2030

- Impact: Fundamental shift in compute allocation; inference-optimized chips (TPUs, specialized ASICs) gain market share over training GPUs
- Confidence: High
- Source: byteiota analysis (2 weeks ago)

### Deployment | H100 GPU Prices Collapsed 64-75% in 14 Months
- What: 
H100 cloud rental dropped to $2.99/hour, down 64-75% in 14 months from $8-10/hour

- Impact: Accelerates shift from GPU ownership to cloud rental; pressure on NVIDIA margins; validates inference optimization over raw compute
- Confidence: High
- Source: byteiota (2 weeks ago)

### Second-order | Data Center Energy Crisis Goes Bipartisan
- What: 
Bernie Sanders and Ron DeSantis both oppose data center boom; Sanders calls for national construction moratorium
 and 
Maryland utility bills rose 37% last year due to data centers

- Impact: Political risk to AI infrastructure buildout; regulatory bottlenecks likely in 2026; affects datacenter site selection and permitting timelines
- Confidence: High
- Source: CNBC, Tom's Hardware (last 24 hours)

### Second-order | Goldman Warns on Electricity Price Inflation
- What: 
Goldman Sachs analysts warn electricity prices will keep rising as data center growth collides with constrained supply due to regulatory barriers and material shortages

- Impact: Increases total cost of AI ownership; accelerates behind-the-meter power generation (nuclear, gas); potential inflation spillover
- Confidence: High
- Source: CNBC (7 hours ago)

### Second-order | Anthropic Pledges to Pay 100% of Grid Upgrade Costs
- What: 
Anthropic promises to pay 100% of grid upgrade costs, bring new power online, and invest in systems to reduce grid strain

- Impact: Sets new precedent for AI company infrastructure obligations; shifts capex burden from utilities to tech companies; may accelerate buildouts if adopted widely
- Confidence: Medium
- Source: Tom's Hardware (12 hours ago)

## Causal Updates

1. **Memory as AI Bottleneck**: The memory market ($551B) now exceeding foundry revenue ($218B) by 2.5x confirms that HBM/memory is the true supply constraint, not logic chips. This explains why SK Hynix/Samsung have pricing power.

2. **Inference-Training Flip**: The 80% of lifecycle costs going to inference (not training) fundamentally changes who wins in AI hardware. TPU/ASIC makers gain vs NVIDIA's training-optimized GPUs.

3. **Political Backlash Loop**: Rising electricity bills → voter anger → bipartisan opposition → permitting delays → slower datacenter buildout → chip demand uncertainty. This creates 12-18 month lag in chip orders.

4. **Oversupply Risk Emerging**: SMIC's warning about "10 years in 2 years" buildout + H100 price collapse signals potential AI infrastructure overbuild similar to 2001 fiber optic bust.

## Predictions

**Q2-Q3 2026 (70% confidence)**: Memory pricing power sustains through 2026 as HBM supply remains tight. SK Hynix/Micron outperform NVIDIA on margins.

**H2 2026 (60% confidence)**: First major AI datacenter project cancellation or delay due to permitting/grid issues triggers 15-20% correction in AI infrastructure stocks.

**2027 (55% confidence)**: Inference-optimized chip market (TPUs, Groq, Cerebras) reaches 30%+ share of AI compute spending, up from ~15% today, as economics shift from training to deployment.

**Low confidence risk (30%)**: If Bernie Sanders moratorium gains traction or Virginia-style "data centers pay" rules spread to 5+ states, could see 40-50% reduction in US datacenter construction plans by end of 2026.

---

*Generated automatically by intelligence-pulse.sh*
